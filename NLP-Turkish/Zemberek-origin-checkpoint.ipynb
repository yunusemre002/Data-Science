{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zemberek-python in c:\\users\\demir\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime>=4.8 in c:\\users\\demir\\anaconda3\\lib\\site-packages (from zemberek-python) (4.8)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\demir\\anaconda3\\lib\\site-packages (from zemberek-python) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install zemberek-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-25 11:28:21,672 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 10.805814981460571\n",
      "\n",
      "Yrn okua gidicem\n",
      "yarın oksa gideceğim \n",
      "\n",
      "Tmm, yarin havuza giricem ve aksama kadar yaticam :)\n",
      "tamam , yarın havuza gireceğim ve akşama kadar yatıcam :) \n",
      "\n",
      "ah aynen ya annemde fark ettı siz evinizden cıkmayın diyo\n",
      "ah aynen ya annemde fark etti siz evinizden çıkmayın diyor \n",
      "\n",
      "gercek mı bu? Yuh! Artık unutulması bile beklenmiyo\n",
      "gerçek mi bu ? yuh ! artık uyutulması bile beklenmiyor \n",
      "\n",
      "Hayır hayat telaşm olmasa alacam buraları gökdelen dikicem.\n",
      "hayır hayat telaşı olmasa alacam buraları gökdelen dikeceğim . \n",
      "\n",
      "yok hocam kesınlıkle oyle birşey yok\n",
      "yok hocam kesinlikle öyle bir şey yok \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "\n",
    "examples = [\"Yrn okua gidicem\",\n",
    "            \"Tmm, yarin havuza giricem ve aksama kadar yaticam :)\",\n",
    "            \"ah aynen ya annemde fark ettı siz evinizden cıkmayın diyo\",\n",
    "            \"gercek mı bu? Yuh! Artık unutulması bile beklenmiyo\",\n",
    "            \"Hayır hayat telaşm olmasa alacam buraları gökdelen dikicem.\",\n",
    "            \"yok hocam kesınlıkle oyle birşey yok\"]\n",
    "         \n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "\n",
    "# SENTENCE NORMALIZATION\n",
    "normalizer = TurkishSentenceNormalizer(morphology)\n",
    "\n",
    "for example in examples:\n",
    "    print(example)\n",
    "    print(normalizer.normalize(example), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okuyablirim = okuyabilirim\n",
      "tartısıyor = tartışıyor tartılıyor\n",
      "Ankar'ada = Ankara'da Ankara'ya Ankara'dan Ankara'ma Ankaray'da Ankaray'a Antara'da Ankara'na Anakara'da Ankara'mda Angara'da Ankara'ca Ankara'nda\n",
      "knlıca = kanlıca kanlıca anlıca kalıca onlıca unlıca kılıca kınlıca\n",
      "yapablrim = \n",
      "kıredi = kredi küredi\n",
      "geldm = geldi geldim gelem gelim\n",
      "geliyom = geliyor geliyim\n",
      "aldm = aldı alım aldım alem alim alim alam aldi aldo Aldo'm Aldi'm alda Al'da Al'ım Al'dım Al'dı\n",
      "asln = asla aslan aslan aslı aslı asli aslen asan asın As'lan As'lın As'ın assn aslin As'la aslın As'lı asin Aslı'n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc = TurkishSpellChecker(morphology)\n",
    "# SPELLING SUGGESTION\n",
    "li = [\"okuyablirim\", \"tartısıyor\", \"Ankar'ada\", \"knlıca\", \"yapablrim\", \"kıredi\", \"geldm\", \"geliyom\", \"aldm\", \"asln\"]\n",
    "for word in li:\n",
    "    print(word + \" = \" + ' '.join(sc.suggest_for_word(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İnsanoğlu aslında ne para ne sevgi ne kariyer ne şöhret ne de çevre ile sonsuza dek mutlu olabilecek bir yapıya sahiptir.\n",
      "Dış kaynaklardan gelebilecek bu mutluluklar sadece belirli bir zaman için insanı mutlu kılıyor.\n",
      "Kişi bu kaynakları elde ettiği zaman belirli bir dönem için kendini iyi hissediyor, ancak alışma dönemine girdiği andan itibaren bu iyilik hali hızla tükeniyor.\n",
      "Mutlu olma sanatının özü bu değildir.\n",
      "Gerçek mutluluk, kişinin her türlü olaya ve duruma karşı kendini pozitif tutarak mutlu hissedebilmesi halidir.\n",
      "Bu davranış şeklini edinen insan, zor günlerde güçlü, mutlu günlerde zevk alan biri olur ve mutluluğu kalıcı kılar.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SENTENCE BOUNDARY DETECTION\n",
    "extractor = TurkishSentenceExtractor()\n",
    "\n",
    "text = \"İnsanoğlu aslında ne para ne sevgi ne kariyer ne şöhret ne de çevre ile sonsuza dek mutlu olabilecek bir \" \\\n",
    "       \"yapıya sahiptir. Dış kaynaklardan gelebilecek bu mutluluklar sadece belirli bir zaman için insanı mutlu \" \\\n",
    "       \"kılıyor. Kişi bu kaynakları elde ettiği zaman belirli bir dönem için kendini iyi hissediyor, ancak alışma \" \\\n",
    "       \"dönemine girdiği andan itibaren bu iyilik hali hızla tükeniyor. Mutlu olma sanatının özü bu değildir. Gerçek \" \\\n",
    "       \"mutluluk, kişinin her türlü olaya ve duruma karşı kendini pozitif tutarak mutlu hissedebilmesi halidir. Bu \" \\\n",
    "       \"davranış şeklini edinen insan, zor günlerde güçlü, mutlu günlerde zevk alan biri olur ve mutluluğu kalıcı \" \\\n",
    "       \"kılar. \"\n",
    "\n",
    "sentences = extractor.from_paragraph(text)\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kale:Noun] kale:Noun+A3sg+m:P1sg+in:Gen\n",
      "[Kale:Noun, Prop] kale:Noun+A3sg+m:P1sg+in:Gen\n",
      "[kalem:Noun] kalem:Noun+A3sg+in:Gen\n",
      "[kalem:Noun] kalem:Noun+A3sg+in:P2sg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SINGLE WORD MORPHOLOGICAL ANALYSIS\n",
    "results = morphology.analyze(\"kalemin\")\n",
    "for result in results:\n",
    "    print(result)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content =  Saat\n",
      "Type =  Word\n",
      "Start =  0\n",
      "Stop =  3 \n",
      "\n",
      "Content =  12:00\n",
      "Type =  Time\n",
      "Start =  5\n",
      "Stop =  9 \n",
      "\n",
      "Content =  .\n",
      "Type =  Punctuation\n",
      "Start =  10\n",
      "Stop =  10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZATION\n",
    "tokenizer = TurkishTokenizer.DEFAULT\n",
    "\n",
    "tokens = tokenizer.tokenize(\"Saat 12:00.\")\n",
    "for token in tokens:\n",
    "    print('Content = ', token.content)\n",
    "    print('Type = ', token.type_.name)\n",
    "    print('Start = ', token.start)\n",
    "    print('Stop = ', token.end, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
